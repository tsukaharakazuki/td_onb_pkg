# このWorkflowについて
LDAにて行動データ、購買データなどのトランザクションデータからクラスタリング処理を行います。

## ワークフロー構成

### 1. トレーニングワークフロー（td_lda_training.dig）
- 学習データの準備
- LDAモデルの学習
- モデルの保存（チャンク分割方式）
- 重みデータの保存

### 2. 予測ワークフロー（td_lda_predict.dig）
- 予測データの準備
- 保存済みモデルの読み込み
- クラスタ予測の実行
- 予測結果の保存

## データ保存方式

### モデルデータ
- 大きなモデルデータはTreasureDataのフィールドサイズ制限を回避するため、100KBのチャンクに分割して保存
- `model_${name}`テーブルに以下の構造で保存:
  - `time`: タイムスタンプ
  - `chunk_id`: チャンク番号（0から始まる）
  - `total_chunks`: 総チャンク数
  - `model_data`: Base64エンコードされたモデルデータのチャンク
  - `n_cluster`: クラスタ数

### 予測時のモデル復元
- 最新のタイムスタンプのモデルを自動的に選択
- 全チャンクを順番に結合してモデルを復元
- チャンク数の整合性を検証

## テーブル構成

### 入力テーブル
- `train_ds_${name}`: 学習用データセット
- `tmp_train_ds_${name}`: 一時的な学習データ

### 出力テーブル
- `weights_${name}`: LDAの重み情報
- `model_${name}`: シリアライズされたモデル（チャンク分割）
- `pred_${name}`: 予測結果
- `history_${name}`: 実行履歴とパラメータ

## 実行方法

### トレーニングの実行
```bash
td workflow run td_lda_training.dig
```

### 予測の実行
```bash
td workflow run td_lda_predict.dig
```

## 注意事項
- トレーニングを実行してモデルを保存してから予測を実行してください
- モデルデータが大きい場合、自動的に複数のチャンクに分割されます
- 予測時は最新のモデルが自動的に使用されます